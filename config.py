VOCAB_SIZE = 50257
MAX_SEQ_LENGTH = 100
EMBED_DIM = 64
NUM_LAYERS = 2
DROPOUT = 0.1
LEARNING_RATE = 1e-3
BATCH_SIZE = 8
EPOCHS = 10
MODEL_SAVE_PATH = "models/quantum_gpt_mini.pth"
